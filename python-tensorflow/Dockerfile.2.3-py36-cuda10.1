FROM lablup/common-base:cuda10.1

RUN python3 -m pip uninstall --no-cache-dir -y \
        absl-py \
        tensorflow==2.4.0 tensorboard tensorflow-serving-api tensorflow-text
RUN python3 -m pip install --no-cache-dir \
        tfx-bsl==0.23.0 \
	tfx==0.23.0 \
        tensorflow==2.3.2 \
#	tensorboard==2.3.0 \
	tensorflow-serving-api==2.3.0 \
	tensorflow-text==2.3.0

WORKDIR /tmp
COPY ./requirements.tf.txt /tmp

RUN  python3 -m pip install --no-cache-dir \
        -r  requirements.tf.txt \
	--ignore-installed && \
#     python3 -m pip install --no-cache-dir tensorboard==2.3.0 && \	
    rm -f /tmp/requirements.tf.txt

RUN python3 -m pip install --extra-index-url \
     https://developer.download.nvidia.com/compute/redist nvidia-dali-cuda100 \
       && \
    python3 -m pip install --extra-index-url \
     https://developer.download.nvidia.com/compute/redist nvidia-dali-tf-plugin-cuda100

# Install Horovod, temporarily using CUDA stubs
RUN ldconfig /usr/local/cuda/targets/x86_64-linux/lib/stubs && \
    HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_GPU_BROADCAST=NCCL HOROVOD_NCCL_LINK=SHARED \
    HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITHOUT_PYTORCH=1 HOROVOD_WITHOUT_MXNET=1\
    HOROVOD_GPU=CUDA \
    python3 -m pip install --no-cache-dir horovod==0.19.5 && \
    ldconfig

    
COPY ./service-defs /etc/backend.ai/service-defs
# Install ipython kernelspec
Run python3 -m ipykernel install --display-name "TensorFlow 2.3 on Python 3.6 & CUDA 10.1" && \
    cat /usr/local/share/jupyter/kernels/python3/kernel.json

# Copy Backend.Ai multi-node support
COPY runner-scripts/bootstrap.sh runner-scripts/setup_multinode.py /opt/container/

# Backend.AI specifics
LABEL ai.backend.kernelspec="1" \
      ai.backend.envs.corecount="OPENBLAS_NUM_THREADS,OMP_NUM_THREADS,NPROC" \
      ai.backend.features="batch query uid-match user-input" \
      ai.backend.base-distro="ubuntu16.04" \
      ai.backend.resource.min.cpu="1" \
      ai.backend.resource.min.mem="1g" \
      ai.backend.resource.min.cuda.device=0 \
      ai.backend.resource.min.cuda.shares=0 \
      ai.backend.runtime-type="python" \
      ai.backend.runtime-path="/usr/bin/python3" \
      ai.backend.service-ports="ipython:pty:3000,jupyter:http:8081,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080"

WORKDIR /home/work
# vim: ft=dockerfile
