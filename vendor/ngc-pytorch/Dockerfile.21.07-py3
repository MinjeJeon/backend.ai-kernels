FROM nvcr.io/nvidia/pytorch:21.07-py3
# NVIDIA PyTorch with Python 3.8 (CONDA)

ENV DEBIAN_FRONTEND=noninteractive \
    MPLBACKEND=Svg \
    PIP_IGNORE_INSTALLED=0 \
    PYTHONUNBUFFERED=1 \
    LD_LIBRARY_PATH="/usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu" \
    PATH="/usr/local/nvm/versions/node/v14.8.0/bin:/opt/conda/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin:/usr/local/src/lightgbm/LightGBM:/usr/local/bin/mecab" \
    mecab_dicdir=/usr/local/lib/mecab/dic/mecab-ko-dic \
    CPLUS_INCLUDE_PATH=/usr/include/gdal \
    C_INCLUDE_PATH=/usr/include/gdal \
    LANG=C.UTF-8

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
	automake \
	fonts-nanum \
	fonts-nanum-coding \
	fonts-nanum-extra \
	pdsh \
	gfortran \
	htop \
	ffmpeg \
	libasound2-dev \
	libatlas-base-dev \
	libavresample-dev \
	libdc1394-22-dev \
	libeigen3-dev \
	libfaac-dev \
	libgdal-dev \
	libgflags-dev \
	libgoogle-glog-dev \
	libgphoto2-dev \
	libgstreamer-plugins-base1.0-dev \
	libgstreamer1.0-dev \
	libgtk-3-dev \
	libhdf5-dev \	
	libmp3lame-dev \
	libopenblas-dev \
	libopencore-amrnb-dev \
	libopencore-amrwb-dev \
	libprotobuf-dev \
	libtheora-dev \
	libvorbis-dev \
	libx264-dev \
	libxext6 \
	libxrender-dev \
	libxvidcore-dev \
	mercurial \
	ncurses-term \
	protobuf-compiler \
	v4l-utils \	
	x264 \
       	openjdk-8-jdk \
        libsm6 \
        libtbb-dev 

# Install CUDA-11.3 + cuDNN 8.2.0
RUN ln -s /usr/lib/x86_64-linux-gnu/libcudnn.so.8.2.0 /usr/local/cuda/lib64/libcudnn.so && \
    rm -rf /var/lib/apt/lists/* && \
    ldconfig

# nvtop install
WORKDIR /tmp
RUN git clone https://github.com/Syllo/nvtop.git && \
    mkdir -p nvtop/build && \
    cd /tmp/nvtop/build && \
    cmake .. && \
    cmake .. -DNVML_RETRIEVE_HEADER_ONLINE=True && \
    make -j$(nproc) && \
    make install

RUN update-alternatives --install /opt/conda/bin/python python /opt/conda/bin/python3 2

WORKDIR /tmp
RUN curl https://bootstrap.pypa.io/get-pip.py | python3 && \
    python3 -m pip install --no-cache-dir -U setuptools pip 

WORKDIR /tmp
# install NLP packages *mecab-ko & khai*
RUN curl -LO https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz && \
    tar zxfv mecab-0.996-ko-0.9.2.tar.gz && \
    cd mecab-0.996-ko-0.9.2 && \
    ./configure && \
    make -j$(nproc) && \
    make check && \
    make install

RUN echo "Install mecab-ko-dic" && \
    cd /tmp && \
    ldconfig && \
    curl -LO https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz && \
    tar -zxvf mecab-ko-dic-2.1.1-20180720.tar.gz && \
    cd mecab-ko-dic-2.1.1-20180720 && \
    ./autogen.sh && \
    ./configure && \
    make -j$(nproc) && \
    sh -c 'echo "dicdir=/usr/local/lib/mecab/dic/mecab-ko-dic" > /usr/local/etc/mecabrc' && \
    make install && \
    cd /tmp && \
    git clone https://bitbucket.org/eunjeon/mecab-python-0.996.git && \
    python3 -m pip install /tmp/mecab-python-0.996

RUN curl -sL https://deb.nodesource.com/setup_14.x | bash - && \
    apt-get update -y && \
    apt-get install -y nodejs

WORKDIR /tmp
RUN git clone -q --branch=v0.3.14 git://github.com/xianyi/OpenBLAS.git && \
    cd OpenBLAS && \
    make DYNAMIC_ARCH=1 NO_AFFINITY=1 NUM_THREADS=48 FC=gfortran && \
    make install
RUN git clone --recursive https://github.com/bodono/scs-python.git  && \
    cd /tmp/scs-python && \
    python setup.py install --scs --gpu

RUN /opt/conda/bin/conda install -c conda-forge opencv ffmpeg spacy

RUN /opt/conda/bin/python3 -m pip install --no-cache-dir \
    	    Cython==0.29.22 \
	    tornado==6.1 \
	    pystan==3.0.1 \
	    pycairo==1.20.0 \
	    jupyter==1.0.0 \
	    typeguard==2.11.1 \
	    python-language-server[all] \	    
	    matplotlib==3.4.1
ENV SCIPY_VERSION 1.7.1
# Install scipy
RUN cd /tmp && \
    git clone --branch=v${SCIPY_VERSION} --depth=1 https://github.com/scipy/scipy.git scipy && \
    cd scipy && \
    git checkout -b v${SCIPY_VERSION} && \
    git submodule update --init && \
    cp site.cfg.example site.cfg && \
    python3 -m pip install -U --no-cache-dir \
	numpy==1.21.1 \
	pandas==1.3.3 \
	pythran \
        scikit-learn==1.0 \
	hypothesis==6.23.2 \
	python-lsp-server \
	&& \
    python3 setup.py install 
	    
WORKDIR /tmp
COPY ./requirements.txt /tmp
RUN /opt/conda/bin/python3 -m pip install --no-cache-dir --ignore-installed -r requirements.txt && \
    rm -f /tmp/*.whl /tmp/requirements.txt

# install git-lfs
WORKDIR /tmp
RUN curl -sLO https://github.com/git-lfs/git-lfs/releases/download/v2.13.3/git-lfs-linux-amd64-v2.13.3.tar.gz && \
    tar -zxf git-lfs-linux-amd64-v2.13.3.tar.gz && \
    bash install.sh && \
    rm -rf /tmp/*

WORKDIR /tmp
RUN git clone https://github.com/aristocratos/bashtop.git && \
    cd bashtop && \
    make install

RUN curl -fL https://github.com/cdr/code-server/releases/download/v3.12.0/code-server-3.12.0-linux-amd64.tar.gz | tar -C /usr/local/lib -xz && \
    mv /usr/local/lib/code-server-3.12.0-linux-amd64 /usr/local/lib/code-server-3.12.0 && \
    ln -s /usr/local/lib/code-server-3.12.0/bin/code-server /usr/local/bin/code-server

# Install Open MPI
RUN mkdir /tmp/openmpi && \
    cd /tmp/openmpi && \
    wget https://download.open-mpi.org/release/open-mpi/v4.1/openmpi-4.1.0.tar.gz && \
    tar zxf openmpi-4.1.0.tar.gz && \
    cd openmpi-4.1.0 && \
    ./configure --enable-orterun-prefix-by-default && \
    make -j $(nproc) all && \
    make install && \
    ldconfig && \
    rm -rf /tmp/openmpi*
# Create a wrapper for OpenMPI to allow running as root by default
RUN mv /usr/local/bin/mpirun /usr/local/bin/mpirun.real && \
    echo '#!/bin/bash' > /usr/local/bin/mpirun && \
    echo 'mpirun.real --allow-run-as-root "$@"' >> /usr/local/bin/mpirun && \
    chmod a+x /usr/local/bin/mpirun

# Configure OpenMPI to run good defaults:
RUN echo "btl_tcp_if_exclude = lo,docker0" >> /usr/local/etc/openmpi-mca-params.conf

# Install Horovod, temporarily using CUDA stubs
RUN ldconfig /usr/local/cuda/targets/x86_64-linux/lib/stubs && \
    HOROVOD_CUDA_HOME=$CONDA_PREFIX HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_GPU_BROADCAST=NCCL HOROVOD_NCCL_LINK=SHARED \
    HOROVOD_WITHOUT_TENSORFLOW=1 HOROVOD_WITH_PYTORCH=1 HOROVOD_WITHOUT_MXNET=1 \
    pip install --no-cache-dir horovod==0.21.3 && \
    ldconfig

RUN python3 -m pip install --no-cache-dir \
    	    mpi4py==3.0.3 \
	    nni==2.1 \
	    mlflow==1.15.0 \
	    scikit-nni==0.1.1

RUN jupyter nbextensions_configurator enable && \
    jupyter contrib nbextension install && \
    jupyter nbextension enable --py --sys-prefix widgetsnbextension && \
    jupyter serverextension enable --py jupyterlab --sys-prefix && \
    jupyter labextension install --no-build @jupyter-widgets/jupyterlab-manager && \
    jupyter labextension install --no-build @krassowski/jupyterlab-lsp && \
    jupyter serverextension enable --py jupyter_lsp && \
    jupyter labextension install --no-build @jupyterlab/toc && \
    jupyter nbextension enable execute_time/ExecuteTime && \
    jupyter nbextension enable toc2/main && \
    jupyter lab build

RUN apt autoclean && \
    sed -i 's/source \/usr\/local\/nvm\/nvm.sh//' /etc/bash.bashrc && \
    ln -sf /usr/share/terminfo/x/xterm-color /usr/share/terminfo/x/xterm-256color && \
    rm -rf /var/lib/apt/lists/* && \	
    rm -rf /root/.cache && \
    rm -rf /tmp/*

RUN /opt/conda/bin/python3 -m ipykernel install \
        --prefix=/opt/conda/ \
        --display-name "PyTorch 1.10 (NGC 21.07/Python 3.8 Conda) on Backend.AI" && \
    cat /opt/conda/share/jupyter/kernels/python3/kernel.json

# Backend.AI specifics
COPY ./service-defs /etc/backend.ai/service-defs
COPY ./runner-scripts/bootstrap.sh runner-scripts/setup_multinode.py /opt/container/

LABEL ai.backend.kernelspec="1" \
      ai.backend.envs.corecount="OPENBLAS_NUM_THREADS,OMP_NUM_THREADS,NPROC" \
      ai.backend.features="batch query uid-match user-input" \
      ai.backend.base-distro="ubuntu16.04" \
      ai.backend.accelerators="cuda" \
      ai.backend.resource.min.cpu="1" \
      ai.backend.resource.min.mem="1g" \
      ai.backend.resource.min.cuda.device=1 \
      ai.backend.resource.min.cuda.shares=0.1 \
      ai.backend.base-distro="ubuntu16.04" \
      ai.backend.runtime-type="python" \
      ai.backend.runtime-path="/opt/conda/bin/python3" \
      ai.backend.service-ports="ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080"
  
WORKDIR /home/work
# vim: ft=dockerfile
